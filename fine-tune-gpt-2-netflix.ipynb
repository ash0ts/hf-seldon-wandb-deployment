{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQdVGahMHAZL"
   },
   "source": [
    "# Finetuning GPT2 with Netflix Descriptions\n",
    "Taken ref from: https://www.kaggle.com/code/nulldata/fine-tuning-gpt-2-to-generate-netlfix-descriptions/notebook\n",
    "\n",
    "Which took ref from: https://medium.com/geekculture/fine-tune-eleutherai-gpt-neo-to-generate-netflix-movie-descriptions-in-only-47-lines-of-code-40c9b4c32475"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pf0f415jHBBJ"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 179,
     "status": "ok",
     "timestamp": 1665424025508,
     "user": {
      "displayName": "Anish Shah",
      "userId": "05913492621931233323"
     },
     "user_tz": 240
    },
    "id": "R9TdYzhlzMwb"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 32770,
     "status": "ok",
     "timestamp": 1665424058457,
     "user": {
      "displayName": "Anish Shah",
      "userId": "05913492621931233323"
     },
     "user_tz": 240
    },
    "id": "-erHYjhc9jic"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "if IN_COLAB:\n",
    "    \n",
    "    #Remove not needed python versions to free space\n",
    "    !rm -rf \"/usr/local/lib/python2.7\"\n",
    "    !rm -rf \"/usr/lib/python2.7\"\n",
    "\n",
    "    # Clone the repo.\n",
    "    # !git clone \"\"\n",
    "\n",
    "    # Change the working directory to the repo root.\n",
    "    # %cd\n",
    "\n",
    "    # Add the repo root to the Python path.\n",
    "    # import sys, os\n",
    "    # sys.path.append(os.getcwd())\n",
    "    \n",
    "    #Install packages not native to colab\n",
    "    !pip install python-dotenv\n",
    "    !pip install transformers\n",
    "    !pip install transformers[onnx]\n",
    "    !pip install evaluate\n",
    "    !pip install wandb --upgrade\n",
    "\n",
    "    # !pip install pandas-profiling --upgrade\n",
    "\n",
    "    #Mount GDrive to access .env file\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    #Load env file\n",
    "    #NOTE: gdrive wont allow you to mount dotfiles\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(\"./gdrive/MyDrive/my_env_file\")\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3951,
     "status": "ok",
     "timestamp": 1665424064614,
     "user": {
      "displayName": "Anish Shah",
      "userId": "05913492621931233323"
     },
     "user_tz": 240
    },
    "id": "SPzdMC0K-SB6",
    "outputId": "b7ca1c49-35bd-4d4a-faf1-95f9e378498c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ma-sh0ts\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1665424065081,
     "user": {
      "displayName": "Anish Shah",
      "userId": "05913492621931233323"
     },
     "user_tz": 240
    },
    "id": "UVvK1ZmK--hz",
    "outputId": "55df1a10-dc71-4d9e-ac78-94b63803c0fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 11 05:19:24 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   73C    P8    20W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   74C    P8    22W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla T4            Off  | 00000000:00:06.0 Off |                    0 |\n",
      "| N/A   73C    P8    21W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla T4            Off  | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   69C    P8    18W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 645,
     "status": "ok",
     "timestamp": 1665424065725,
     "user": {
      "displayName": "Anish Shah",
      "userId": "05913492621931233323"
     },
     "user_tz": 240
    },
    "id": "kfJ9yjft_GX8",
    "outputId": "79ec00a9-cb8b-4f85-aaf7-84f053ada287"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8e1084ba90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOcn3keAH6bX"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "referenced_widgets": [
      "f4724017933549c4bb9ed4e6db07f133",
      "4101a1f8b3cd4cf1a14857f8563d396d",
      "764a9f98d95041348ba29b2c0f7d31e9",
      "dc1c9d6de8d143579ca742460a8cfba6",
      "00159f4301e24fd983196b2bb34085b3",
      "f2db562c04034a8b948c64ab7529b719",
      "185bc02c28d743b9a5142767a1ecbd62",
      "da751070ba884c9298d1e2afa8b567c1",
      "47f1971420aa4e95baf39f927ec38757",
      "d13385b298414e0f8d14ece8ae71317d",
      "ebbfda788fdd470f97dd977eef21d75f"
     ]
    },
    "executionInfo": {
     "elapsed": 3433,
     "status": "ok",
     "timestamp": 1665424069150,
     "user": {
      "displayName": "Anish Shah",
      "userId": "05913492621931233323"
     },
     "user_tz": 240
    },
    "id": "LqCkBLRHHvhk",
    "outputId": "ba30498b-d0c6-4e2f-e1b3-d78e894d5183"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, random_split\n",
    "from transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1665424069203,
     "user": {
      "displayName": "Anish Shah",
      "userId": "05913492621931233323"
     },
     "user_tz": 240
    },
    "id": "uGQ08PjnI6no"
   },
   "outputs": [],
   "source": [
    "#These settings are set for 4 x T4s\n",
    "_model_conf = {\n",
    "    \"dataset_artifact\": \"netflix-shows\",\n",
    "    \"dataset_path\": \"data/netflix_titles.csv\",\n",
    "    \"dataset_version\": \"latest\",\n",
    "    \"text_column\": \"description\",\n",
    "    \"base_gpt_model\": \"gpt2-medium\",\n",
    "    \"bos_token\": '<|startoftext|>',\n",
    "    \"eos_token\": '<|endoftext|>',\n",
    "    \"pad_token\": '<|pad|>',\n",
    "    \"train_split\": 0.99,\n",
    "    \"num_train_epochs\": 10,\n",
    "    \"logging_steps\": 1,\n",
    "    \"save_steps\": 500,\n",
    "    \"per_device_train_batch_size\": 16,\n",
    "    \"per_device_eval_batch_size\": 16,\n",
    "    \"warmup_steps\": 10,\n",
    "    \"weight_decay\": 0.05,\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"eval_steps\": 10,\n",
    "    \"evaluation_metrics\": [\n",
    "        \"bleu\", \n",
    "        \"google_bleu\", \n",
    "        # \"mauve\"\n",
    "                           ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1665424069204,
     "user": {
      "displayName": "Anish Shah",
      "userId": "05913492621931233323"
     },
     "user_tz": 240
    },
    "id": "9G0qvtc5Kowu"
   },
   "outputs": [],
   "source": [
    "project_name = \"gpt2-netflix\"\n",
    "run_name = \"finetune_gpt2\"\n",
    "run_type = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 65
    },
    "executionInfo": {
     "elapsed": 10784,
     "status": "ok",
     "timestamp": 1665424079982,
     "user": {
      "displayName": "Anish Shah",
      "userId": "05913492621931233323"
     },
     "user_tz": 240
    },
    "id": "J8sjy_mTKh6e",
    "outputId": "86017d98-7f64-4fc5-8baf-926dfc513956"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/hf-seldon-wandb-deployment/wandb/run-20221011_051926-tat9q1u7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/a-sh0ts/gpt2-netflix/runs/tat9q1u7\" target=\"_blank\">finetune_gpt2</a></strong> to <a href=\"https://wandb.ai/a-sh0ts/gpt2-netflix\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "        project=project_name, job_type=run_type, name=run_name, config = _model_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SWUjL41aLCzf"
   },
   "outputs": [],
   "source": [
    "model_conf = run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "S3yXOpYwK8dG"
   },
   "outputs": [],
   "source": [
    "dataset_artifact = model_conf[\"dataset_artifact\"]\n",
    "dataset_version = model_conf[\"dataset_version\"]\n",
    "dataset_path = model_conf[\"dataset_path\"]\n",
    "text_column = model_conf[\"text_column\"]\n",
    "\n",
    "base_gpt_model = model_conf[\"base_gpt_model\"]\n",
    "bos_token = model_conf[\"bos_token\"]\n",
    "eos_token = model_conf[\"eos_token\"]\n",
    "pad_token = model_conf[\"pad_token\"]\n",
    "\n",
    "train_split = model_conf[\"train_split\"]\n",
    "\n",
    "num_train_epochs = model_conf[\"num_train_epochs\"]\n",
    "logging_steps = model_conf[\"logging_steps\"]\n",
    "save_steps = model_conf[\"save_steps\"]\n",
    "per_device_train_batch_size = model_conf[\"per_device_train_batch_size\"]\n",
    "per_device_eval_batch_size = model_conf[\"per_device_eval_batch_size\"]\n",
    "warmup_steps = model_conf[\"warmup_steps\"]\n",
    "weight_decay = model_conf[\"weight_decay\"]\n",
    "\n",
    "evaluation_strategy = model_conf[\"evaluation_strategy\"]\n",
    "eval_steps = model_conf[\"eval_steps\"]\n",
    "evaluation_metrics = model_conf[\"evaluation_metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12984,
     "status": "ok",
     "timestamp": 1665424103011,
     "user": {
      "displayName": "Anish Shah",
      "userId": "05913492621931233323"
     },
     "user_tz": 240
    },
    "id": "SRgU2Egv-B_1",
    "outputId": "fb180b07-e359-499c-d372-5e32a14642d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 1024)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(base_gpt_model, bos_token=bos_token,\n",
    "                                          eos_token=eos_token, pad_token=pad_token)\n",
    "model = GPT2LMHeadModel.from_pretrained(base_gpt_model).cuda()\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wDaTgjO_LaTm"
   },
   "outputs": [],
   "source": [
    "netflix_dataset_art = run.use_artifact(f\"{dataset_artifact}:{dataset_version}\").get_path(dataset_path)\n",
    "netflix_dataset_path = netflix_dataset_art.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gZVTtNP4bbU5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aedWE0xdMcOV"
   },
   "outputs": [],
   "source": [
    "netflix_descriptions = pd.read_csv(netflix_dataset_path)[text_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oPgZGteqQweG"
   },
   "outputs": [],
   "source": [
    "max_length = max([len(tokenizer.encode(description)) for description in netflix_descriptions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LtQMchnsRBHk"
   },
   "outputs": [],
   "source": [
    "run.config.update({\"max_length\": max_length})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "yIbYhi3EQ1tL"
   },
   "outputs": [],
   "source": [
    "class NetflixDataset(Dataset):\n",
    "    def __init__(self, txt_list, tokenizer, bos_token, eos_token, max_length):\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        self.labels = []\n",
    "        for txt in txt_list:\n",
    "            encodings_dict = tokenizer(bos_token + txt + eos_token, truncation=True,\n",
    "                                       max_length=max_length, padding=\"max_length\")\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LWx2nvmDQ4en"
   },
   "outputs": [],
   "source": [
    "dataset = NetflixDataset(netflix_descriptions, tokenizer, bos_token, eos_token, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 5158,
     "status": "ok",
     "timestamp": 1665424150349,
     "user": {
      "displayName": "Anish Shah",
      "userId": "05913492621931233323"
     },
     "user_tz": 240
    },
    "id": "Uk1wnrlRRQsN"
   },
   "outputs": [],
   "source": [
    "train_size = int(train_split * len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "tENeshCKR5P2"
   },
   "outputs": [],
   "source": [
    "run.config.update({\"train_size\": train_size})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "i9sugpdCRNYr"
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "6f_bHoISqII3"
   },
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Na8qWY7ZrAkB"
   },
   "outputs": [],
   "source": [
    "# bleu = evaluate.load(\"bleu\")\n",
    "# google_bleu = evaluate.load(\"google_bleu\")\n",
    "# mauve = load('mauve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "tbRqN-1hrAoW"
   },
   "outputs": [],
   "source": [
    "text_gen_metrics = evaluate.combine(evaluation_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 5107,
     "status": "ok",
     "timestamp": 1665424192519,
     "user": {
      "displayName": "Anish Shah",
      "userId": "05913492621931233323"
     },
     "user_tz": 240
    },
    "id": "LPJtewd5rGX0"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    prediction_logits, true_encodings = eval_pred\n",
    "    prediction_encodings = np.argmax(prediction_logits, axis=-1)\n",
    "    \n",
    "    true_texts = tokenizer.batch_decode(true_encodings, skip_special_tokens=True)\n",
    "    prediction_texts = tokenizer.batch_decode(prediction_encodings, skip_special_tokens=True)\n",
    "    \n",
    "    del prediction_logits\n",
    "    del true_encodings\n",
    "    del prediction_encodings\n",
    "    gc.collect()\n",
    "    \n",
    "    return text_gen_metrics.compute(predictions=prediction_texts, references=true_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "EW1mrek6SUPP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Ws-nGxlrSU6k"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "DbogDay4SYIS"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir='./results',\n",
    "                                  num_train_epochs=num_train_epochs,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  save_steps=save_steps,\n",
    "                                  per_device_train_batch_size=per_device_train_batch_size,\n",
    "                                  per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "                                  evaluation_strategy=evaluation_strategy,\n",
    "                                  eval_steps=eval_steps,\n",
    "                                  warmup_steps=warmup_steps,\n",
    "                                  weight_decay=weight_decay,\n",
    "                                  logging_dir='./logs',\n",
    "                                  report_to = 'wandb') #🪄🐝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qWgTFWBMXWFt"
   },
   "outputs": [],
   "source": [
    "model_trainer = Trainer(model=model,\n",
    "                        args=training_args,\n",
    "                        train_dataset=train_dataset, \n",
    "                        eval_dataset=val_dataset,\n",
    "                        compute_metrics = compute_metrics,\n",
    "                        data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n",
    "                                                              'attention_mask': torch.stack([f[1] for f in data]),\n",
    "                                                              'labels': torch.stack([f[0] for f in data])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "kLNDgloBXeC1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 8718\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1370\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1370' max='1370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1370/1370 41:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Precisions</th>\n",
       "      <th>Brevity Penalty</th>\n",
       "      <th>Length Ratio</th>\n",
       "      <th>Translation Length</th>\n",
       "      <th>Reference Length</th>\n",
       "      <th>Google Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.019000</td>\n",
       "      <td>3.976054</td>\n",
       "      <td>0.021213</td>\n",
       "      <td>[0.34360189573459715, 0.05987135081642751, 0.009316770186335404, 0.0016277807921866521]</td>\n",
       "      <td>0.897577</td>\n",
       "      <td>0.902481</td>\n",
       "      <td>2110</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.097701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.249600</td>\n",
       "      <td>2.373108</td>\n",
       "      <td>0.029503</td>\n",
       "      <td>[0.3555651797314855, 0.08333333333333333, 0.018301267010793053, 0.0014691478942213516]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.117568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.923000</td>\n",
       "      <td>1.789639</td>\n",
       "      <td>0.055343</td>\n",
       "      <td>[0.3752166377816291, 0.106804867057233, 0.03145539906103286, 0.007839294463498285]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.133709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.827700</td>\n",
       "      <td>1.742040</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>[0.3697442566103164, 0.1109107303877367, 0.03334899013621419, 0.007352941176470588]</td>\n",
       "      <td>0.986653</td>\n",
       "      <td>0.986741</td>\n",
       "      <td>2307</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.133717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.908800</td>\n",
       "      <td>1.716047</td>\n",
       "      <td>0.060227</td>\n",
       "      <td>[0.38109756097560976, 0.11508835523334844, 0.03446647780925401, 0.009364218827008379]</td>\n",
       "      <td>0.981874</td>\n",
       "      <td>0.982036</td>\n",
       "      <td>2296</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.137779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.795400</td>\n",
       "      <td>1.700844</td>\n",
       "      <td>0.056887</td>\n",
       "      <td>[0.38464893153074575, 0.11524500907441017, 0.03451536643026005, 0.007403751233958539]</td>\n",
       "      <td>0.980566</td>\n",
       "      <td>0.980753</td>\n",
       "      <td>2293</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.138180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.767100</td>\n",
       "      <td>1.689114</td>\n",
       "      <td>0.050813</td>\n",
       "      <td>[0.38280226975120035, 0.11307901907356949, 0.03076194983435873, 0.005434782608695652]</td>\n",
       "      <td>0.979694</td>\n",
       "      <td>0.979897</td>\n",
       "      <td>2291</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.135697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.718100</td>\n",
       "      <td>1.679162</td>\n",
       "      <td>0.055227</td>\n",
       "      <td>[0.3854529616724739, 0.11599456275487087, 0.03493862134088763, 0.006407097092163627]</td>\n",
       "      <td>0.981874</td>\n",
       "      <td>0.982036</td>\n",
       "      <td>2296</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.138632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.723200</td>\n",
       "      <td>1.673787</td>\n",
       "      <td>0.054735</td>\n",
       "      <td>[0.38374619730551934, 0.11482820976491863, 0.03155911446066886, 0.00688298918387414]</td>\n",
       "      <td>0.984049</td>\n",
       "      <td>0.984175</td>\n",
       "      <td>2301</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.137317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.730200</td>\n",
       "      <td>1.669682</td>\n",
       "      <td>0.058173</td>\n",
       "      <td>[0.3874619068350022, 0.1213768115942029, 0.03539405379896177, 0.007389162561576354]</td>\n",
       "      <td>0.982309</td>\n",
       "      <td>0.982464</td>\n",
       "      <td>2297</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.740900</td>\n",
       "      <td>1.664849</td>\n",
       "      <td>0.058731</td>\n",
       "      <td>[0.38511749347258484, 0.11815301041195111, 0.03349056603773585, 0.008370260955194485]</td>\n",
       "      <td>0.982744</td>\n",
       "      <td>0.982891</td>\n",
       "      <td>2298</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.139372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.800800</td>\n",
       "      <td>1.662887</td>\n",
       "      <td>0.054123</td>\n",
       "      <td>[0.3862548934319269, 0.11764705882352941, 0.031588873173031586, 0.0063976377952755905]</td>\n",
       "      <td>0.983179</td>\n",
       "      <td>0.983319</td>\n",
       "      <td>2299</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.138694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.671300</td>\n",
       "      <td>1.660906</td>\n",
       "      <td>0.062061</td>\n",
       "      <td>[0.38712483688560245, 0.12081447963800905, 0.036303630363036306, 0.009350393700787402]</td>\n",
       "      <td>0.983179</td>\n",
       "      <td>0.983319</td>\n",
       "      <td>2299</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.694800</td>\n",
       "      <td>1.656548</td>\n",
       "      <td>0.054835</td>\n",
       "      <td>[0.38816362053959963, 0.11815301041195111, 0.0330188679245283, 0.006400787789266372]</td>\n",
       "      <td>0.982744</td>\n",
       "      <td>0.982891</td>\n",
       "      <td>2298</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.139472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.649100</td>\n",
       "      <td>1.661162</td>\n",
       "      <td>0.055391</td>\n",
       "      <td>[0.39166304819800263, 0.11607949412827462, 0.032, 0.0068762278978389]</td>\n",
       "      <td>0.984917</td>\n",
       "      <td>0.985030</td>\n",
       "      <td>2303</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.139910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>1.659103</td>\n",
       "      <td>0.069365</td>\n",
       "      <td>[0.39374185136897, 0.12251356238698011, 0.040037682524729154, 0.012782694198623401]</td>\n",
       "      <td>0.984049</td>\n",
       "      <td>0.984175</td>\n",
       "      <td>2301</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.145274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.635300</td>\n",
       "      <td>1.658009</td>\n",
       "      <td>0.059278</td>\n",
       "      <td>[0.39096437880104257, 0.1211025756891098, 0.03531073446327684, 0.007862407862407862]</td>\n",
       "      <td>0.984483</td>\n",
       "      <td>0.984602</td>\n",
       "      <td>2302</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.646400</td>\n",
       "      <td>1.655831</td>\n",
       "      <td>0.057853</td>\n",
       "      <td>[0.3907745865970409, 0.11815301041195111, 0.0330188679245283, 0.007877892663712457]</td>\n",
       "      <td>0.982744</td>\n",
       "      <td>0.982891</td>\n",
       "      <td>2298</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.572900</td>\n",
       "      <td>1.657979</td>\n",
       "      <td>0.054492</td>\n",
       "      <td>[0.3883326077492381, 0.11865942028985507, 0.03209060877772534, 0.0064039408866995075]</td>\n",
       "      <td>0.982309</td>\n",
       "      <td>0.982464</td>\n",
       "      <td>2297</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.139548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.549700</td>\n",
       "      <td>1.654201</td>\n",
       "      <td>0.052908</td>\n",
       "      <td>[0.38748913987836664, 0.1174875734297334, 0.031073446327683617, 0.005896805896805897]</td>\n",
       "      <td>0.984483</td>\n",
       "      <td>0.984602</td>\n",
       "      <td>2302</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.138795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.506100</td>\n",
       "      <td>1.653614</td>\n",
       "      <td>0.057082</td>\n",
       "      <td>[0.38946910356832026, 0.11815301041195111, 0.03349056603773585, 0.007385524372230428]</td>\n",
       "      <td>0.982744</td>\n",
       "      <td>0.982891</td>\n",
       "      <td>2298</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.629100</td>\n",
       "      <td>1.650396</td>\n",
       "      <td>0.057571</td>\n",
       "      <td>[0.39287266405910476, 0.1166365280289331, 0.03250117757889778, 0.007866273352999017]</td>\n",
       "      <td>0.984049</td>\n",
       "      <td>0.984175</td>\n",
       "      <td>2301</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.618300</td>\n",
       "      <td>1.650245</td>\n",
       "      <td>0.055507</td>\n",
       "      <td>[0.3910783889129493, 0.11666666666666667, 0.031909901454716096, 0.0068560235063663075]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.630700</td>\n",
       "      <td>1.645376</td>\n",
       "      <td>0.055927</td>\n",
       "      <td>[0.394874022589053, 0.11974694984184366, 0.032015065913371, 0.0068796068796068794]</td>\n",
       "      <td>0.984483</td>\n",
       "      <td>0.984602</td>\n",
       "      <td>2302</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.581500</td>\n",
       "      <td>1.647895</td>\n",
       "      <td>0.055242</td>\n",
       "      <td>[0.3949761801645734, 0.12027027027027028, 0.0323791647114031, 0.006366307541625857]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.612100</td>\n",
       "      <td>1.647357</td>\n",
       "      <td>0.057837</td>\n",
       "      <td>[0.3944516688339835, 0.12037871956717763, 0.033818694222639736, 0.007352941176470588]</td>\n",
       "      <td>0.986653</td>\n",
       "      <td>0.986741</td>\n",
       "      <td>2307</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.675500</td>\n",
       "      <td>1.643789</td>\n",
       "      <td>0.053113</td>\n",
       "      <td>[0.39175704989154014, 0.11597472924187725, 0.03149976492712741, 0.005888125613346418]</td>\n",
       "      <td>0.985785</td>\n",
       "      <td>0.985885</td>\n",
       "      <td>2305</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.139747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.466500</td>\n",
       "      <td>1.643808</td>\n",
       "      <td>0.060248</td>\n",
       "      <td>[0.39592367736339984, 0.12133513757329725, 0.03477443609022556, 0.008337420304070623]</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.986313</td>\n",
       "      <td>2306</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.531200</td>\n",
       "      <td>1.654163</td>\n",
       "      <td>0.054904</td>\n",
       "      <td>[0.3952277657266811, 0.11597472924187725, 0.032910202162670425, 0.006378802747791953]</td>\n",
       "      <td>0.985785</td>\n",
       "      <td>0.985885</td>\n",
       "      <td>2305</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.472800</td>\n",
       "      <td>1.651403</td>\n",
       "      <td>0.056377</td>\n",
       "      <td>[0.39679098005203817, 0.12088407758231845, 0.03242481203007519, 0.006866110838646395]</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.986313</td>\n",
       "      <td>2306</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.595000</td>\n",
       "      <td>1.655272</td>\n",
       "      <td>0.059436</td>\n",
       "      <td>[0.38925010836584306, 0.12082957619477007, 0.035697510568341945, 0.00784313725490196]</td>\n",
       "      <td>0.986653</td>\n",
       "      <td>0.986741</td>\n",
       "      <td>2307</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.513700</td>\n",
       "      <td>1.656580</td>\n",
       "      <td>0.061045</td>\n",
       "      <td>[0.3928107405803378, 0.11981981981981982, 0.035194744251525106, 0.00881488736532811]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.480800</td>\n",
       "      <td>1.657163</td>\n",
       "      <td>0.054609</td>\n",
       "      <td>[0.391605365642579, 0.11566156615661566, 0.03234880450070324, 0.006360078277886497]</td>\n",
       "      <td>0.988385</td>\n",
       "      <td>0.988452</td>\n",
       "      <td>2311</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.500700</td>\n",
       "      <td>1.656353</td>\n",
       "      <td>0.060091</td>\n",
       "      <td>[0.39454309224772627, 0.12117117117117117, 0.03660253402158611, 0.007835455435847209]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.456500</td>\n",
       "      <td>1.654262</td>\n",
       "      <td>0.060263</td>\n",
       "      <td>[0.4007798960138648, 0.12392969806219017, 0.03568075117370892, 0.007839294463498285]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.145791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.490100</td>\n",
       "      <td>1.651252</td>\n",
       "      <td>0.063980</td>\n",
       "      <td>[0.3957520589510186, 0.12128043282236249, 0.03757632691404415, 0.00980392156862745]</td>\n",
       "      <td>0.986653</td>\n",
       "      <td>0.986741</td>\n",
       "      <td>2307</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.144728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.539900</td>\n",
       "      <td>1.652714</td>\n",
       "      <td>0.052873</td>\n",
       "      <td>[0.39592367736339984, 0.11592241768155165, 0.03336466165413534, 0.005394801373222168]</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.986313</td>\n",
       "      <td>2306</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.561800</td>\n",
       "      <td>1.651305</td>\n",
       "      <td>0.056059</td>\n",
       "      <td>[0.3924544666088465, 0.11998195760036084, 0.03477443609022556, 0.0063756743501716525]</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.986313</td>\n",
       "      <td>2306</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.461200</td>\n",
       "      <td>1.647568</td>\n",
       "      <td>0.060938</td>\n",
       "      <td>[0.3966189856957087, 0.12173128944995491, 0.03616721465476749, 0.008333333333333333]</td>\n",
       "      <td>0.986653</td>\n",
       "      <td>0.986741</td>\n",
       "      <td>2307</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.144194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.499000</td>\n",
       "      <td>1.648527</td>\n",
       "      <td>0.060949</td>\n",
       "      <td>[0.396529284164859, 0.12364620938628158, 0.035731076633756464, 0.008341511285574092]</td>\n",
       "      <td>0.985785</td>\n",
       "      <td>0.985885</td>\n",
       "      <td>2305</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.144550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.494500</td>\n",
       "      <td>1.653229</td>\n",
       "      <td>0.057350</td>\n",
       "      <td>[0.3968804159445407, 0.12212708427219468, 0.03427230046948357, 0.006859382655560999]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.363400</td>\n",
       "      <td>1.660017</td>\n",
       "      <td>0.051643</td>\n",
       "      <td>[0.3958333333333333, 0.11963882618510158, 0.032455315145813735, 0.004909180166912126]</td>\n",
       "      <td>0.985351</td>\n",
       "      <td>0.985458</td>\n",
       "      <td>2304</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.458200</td>\n",
       "      <td>1.667358</td>\n",
       "      <td>0.057803</td>\n",
       "      <td>[0.39809193408499566, 0.12088407758231845, 0.03571428571428571, 0.006866110838646395]</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.986313</td>\n",
       "      <td>2306</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.144116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.362100</td>\n",
       "      <td>1.661471</td>\n",
       "      <td>0.060940</td>\n",
       "      <td>[0.39566160520607374, 0.125, 0.037611659614480486, 0.007850834151128557]</td>\n",
       "      <td>0.985785</td>\n",
       "      <td>0.985885</td>\n",
       "      <td>2305</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.144936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.431600</td>\n",
       "      <td>1.663668</td>\n",
       "      <td>0.062645</td>\n",
       "      <td>[0.4006938421509107, 0.12494361750112765, 0.03900375939849624, 0.008337420304070623]</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.986313</td>\n",
       "      <td>2306</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.146807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.385300</td>\n",
       "      <td>1.666884</td>\n",
       "      <td>0.058102</td>\n",
       "      <td>[0.39627544391511477, 0.12207207207207207, 0.03613327076489911, 0.0068560235063663075]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.144098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.427200</td>\n",
       "      <td>1.661333</td>\n",
       "      <td>0.057639</td>\n",
       "      <td>[0.39609544468546637, 0.12454873646209386, 0.03714151386929948, 0.006378802747791953]</td>\n",
       "      <td>0.985785</td>\n",
       "      <td>0.985885</td>\n",
       "      <td>2305</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.144550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.420100</td>\n",
       "      <td>1.661019</td>\n",
       "      <td>0.058351</td>\n",
       "      <td>[0.40086580086580087, 0.12426834759117515, 0.03564727954971857, 0.006852667645619187]</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.988024</td>\n",
       "      <td>2310</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.145725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.386800</td>\n",
       "      <td>1.663960</td>\n",
       "      <td>0.059540</td>\n",
       "      <td>[0.3990447242726878, 0.12375790424570912, 0.03670588235294118, 0.0073673870333988214]</td>\n",
       "      <td>0.984917</td>\n",
       "      <td>0.985030</td>\n",
       "      <td>2303</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.145311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.389500</td>\n",
       "      <td>1.664194</td>\n",
       "      <td>0.057065</td>\n",
       "      <td>[0.3955709943551889, 0.12059620596205962, 0.034352941176470586, 0.0068762278978389]</td>\n",
       "      <td>0.984917</td>\n",
       "      <td>0.985030</td>\n",
       "      <td>2303</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>1.660222</td>\n",
       "      <td>0.052173</td>\n",
       "      <td>[0.396529284164859, 0.11913357400722022, 0.03385049365303244, 0.004906771344455349]</td>\n",
       "      <td>0.985785</td>\n",
       "      <td>0.985885</td>\n",
       "      <td>2305</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.399700</td>\n",
       "      <td>1.661739</td>\n",
       "      <td>0.056134</td>\n",
       "      <td>[0.39818024263431545, 0.12032447048219919, 0.03427230046948357, 0.006369426751592357]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.392600</td>\n",
       "      <td>1.660826</td>\n",
       "      <td>0.057323</td>\n",
       "      <td>[0.39800779558250327, 0.11981981981981982, 0.034725480994838104, 0.0068560235063663075]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.412400</td>\n",
       "      <td>1.657049</td>\n",
       "      <td>0.061284</td>\n",
       "      <td>[0.4003466204506066, 0.12167643082469581, 0.036619718309859155, 0.008329250367466928]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.145256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.309000</td>\n",
       "      <td>1.657964</td>\n",
       "      <td>0.058581</td>\n",
       "      <td>[0.39705244906805376, 0.12082957619477007, 0.035227806481916396, 0.007352941176470588]</td>\n",
       "      <td>0.986653</td>\n",
       "      <td>0.986741</td>\n",
       "      <td>2307</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.358500</td>\n",
       "      <td>1.680872</td>\n",
       "      <td>0.057691</td>\n",
       "      <td>[0.3975747076656561, 0.11981981981981982, 0.03566400750821211, 0.0068560235063663075]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.333400</td>\n",
       "      <td>1.684791</td>\n",
       "      <td>0.058528</td>\n",
       "      <td>[0.3986165153480329, 0.12140287769784172, 0.03700234192037471, 0.006842619745845552]</td>\n",
       "      <td>0.989250</td>\n",
       "      <td>0.989307</td>\n",
       "      <td>2313</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.144870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.382300</td>\n",
       "      <td>1.674926</td>\n",
       "      <td>0.056718</td>\n",
       "      <td>[0.3993070593330446, 0.11846846846846847, 0.03613327076489911, 0.006366307541625857]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.311700</td>\n",
       "      <td>1.682399</td>\n",
       "      <td>0.052752</td>\n",
       "      <td>[0.39602248162559445, 0.11735611510791367, 0.035597189695550355, 0.004887585532746823]</td>\n",
       "      <td>0.989250</td>\n",
       "      <td>0.989307</td>\n",
       "      <td>2313</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.358500</td>\n",
       "      <td>1.678736</td>\n",
       "      <td>0.058964</td>\n",
       "      <td>[0.3974025974025974, 0.11886537595677622, 0.036585365853658534, 0.007342143906020558]</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.988024</td>\n",
       "      <td>2310</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.303300</td>\n",
       "      <td>1.678234</td>\n",
       "      <td>0.059525</td>\n",
       "      <td>[0.39965397923875434, 0.1210076473234368, 0.037019681349578254, 0.007334963325183374]</td>\n",
       "      <td>0.988817</td>\n",
       "      <td>0.988879</td>\n",
       "      <td>2312</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.144965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.356400</td>\n",
       "      <td>1.675909</td>\n",
       "      <td>0.058183</td>\n",
       "      <td>[0.4012987012987013, 0.12111661413777577, 0.036116322701688554, 0.006852667645619187]</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.988024</td>\n",
       "      <td>2310</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.145030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.409300</td>\n",
       "      <td>1.675901</td>\n",
       "      <td>0.062542</td>\n",
       "      <td>[0.3997401472498917, 0.12162162162162163, 0.03754106053496011, 0.00881488736532811]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.145481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.325900</td>\n",
       "      <td>1.678664</td>\n",
       "      <td>0.053466</td>\n",
       "      <td>[0.39592367736339984, 0.11953089760938204, 0.03383458646616541, 0.005394801373222168]</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.986313</td>\n",
       "      <td>2306</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.308300</td>\n",
       "      <td>1.675725</td>\n",
       "      <td>0.054612</td>\n",
       "      <td>[0.3950563746747615, 0.11953089760938204, 0.03383458646616541, 0.005885237861696911]</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.986313</td>\n",
       "      <td>2306</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.330700</td>\n",
       "      <td>1.679305</td>\n",
       "      <td>0.055334</td>\n",
       "      <td>[0.3964471403812825, 0.12032447048219919, 0.035211267605633804, 0.005879470847623714]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.437000</td>\n",
       "      <td>1.681830</td>\n",
       "      <td>0.056329</td>\n",
       "      <td>[0.39600521059487626, 0.12149954832881663, 0.034823529411764705, 0.0063850687622789785]</td>\n",
       "      <td>0.984917</td>\n",
       "      <td>0.985030</td>\n",
       "      <td>2303</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.425000</td>\n",
       "      <td>1.676021</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>[0.39948006932409014, 0.12167643082469581, 0.03568075117370892, 0.006859382655560999]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.144532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.301900</td>\n",
       "      <td>1.680176</td>\n",
       "      <td>0.061759</td>\n",
       "      <td>[0.4006923409779316, 0.12196219621962197, 0.03750586029067042, 0.008317025440313111]</td>\n",
       "      <td>0.988385</td>\n",
       "      <td>0.988452</td>\n",
       "      <td>2311</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.145951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.240300</td>\n",
       "      <td>1.703616</td>\n",
       "      <td>0.058323</td>\n",
       "      <td>[0.39835640138408307, 0.11785874943769681, 0.035145267104029994, 0.007334963325183374]</td>\n",
       "      <td>0.988817</td>\n",
       "      <td>0.988879</td>\n",
       "      <td>2312</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.313600</td>\n",
       "      <td>1.701403</td>\n",
       "      <td>0.056869</td>\n",
       "      <td>[0.3933217692974848, 0.11772665764546685, 0.03477443609022556, 0.006866110838646395]</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.986313</td>\n",
       "      <td>2306</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.240200</td>\n",
       "      <td>1.692601</td>\n",
       "      <td>0.055823</td>\n",
       "      <td>[0.3961855223233637, 0.11677186654643823, 0.03475810239549084, 0.006372549019607843]</td>\n",
       "      <td>0.986653</td>\n",
       "      <td>0.986741</td>\n",
       "      <td>2307</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>1.211400</td>\n",
       "      <td>1.698266</td>\n",
       "      <td>0.057851</td>\n",
       "      <td>[0.39705244906805376, 0.11992786293958521, 0.03616721465476749, 0.006862745098039216]</td>\n",
       "      <td>0.986653</td>\n",
       "      <td>0.986741</td>\n",
       "      <td>2307</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.256500</td>\n",
       "      <td>1.701157</td>\n",
       "      <td>0.057762</td>\n",
       "      <td>[0.39584235599826767, 0.11936936936936937, 0.03613327076489911, 0.0068560235063663075]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.277100</td>\n",
       "      <td>1.698006</td>\n",
       "      <td>0.050511</td>\n",
       "      <td>[0.39592367736339984, 0.11637347767253045, 0.03383458646616541, 0.004413928396272682]</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.986313</td>\n",
       "      <td>2306</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.263000</td>\n",
       "      <td>1.696711</td>\n",
       "      <td>0.052146</td>\n",
       "      <td>[0.39462272333044235, 0.11772665764546685, 0.03430451127819549, 0.004904364884747425]</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.986313</td>\n",
       "      <td>2306</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>1.334700</td>\n",
       "      <td>1.699673</td>\n",
       "      <td>0.053620</td>\n",
       "      <td>[0.39844425237683667, 0.11775280898876404, 0.03417602996254682, 0.00537371763556424]</td>\n",
       "      <td>0.989682</td>\n",
       "      <td>0.989735</td>\n",
       "      <td>2314</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.276600</td>\n",
       "      <td>1.696659</td>\n",
       "      <td>0.054032</td>\n",
       "      <td>[0.3922077922077922, 0.11661413777577667, 0.03330206378986867, 0.005873715124816446]</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.988024</td>\n",
       "      <td>2310</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.332700</td>\n",
       "      <td>1.699665</td>\n",
       "      <td>0.055873</td>\n",
       "      <td>[0.3956709956709957, 0.11706438541197658, 0.03470919324577861, 0.006363191385217817]</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.988024</td>\n",
       "      <td>2310</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.234900</td>\n",
       "      <td>1.696212</td>\n",
       "      <td>0.059449</td>\n",
       "      <td>[0.39818024263431545, 0.12122577737719693, 0.03708920187793427, 0.007349338559529643]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.144532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.293200</td>\n",
       "      <td>1.697847</td>\n",
       "      <td>0.062880</td>\n",
       "      <td>[0.39939288811795315, 0.12313937753721245, 0.03806390977443609, 0.008827856792545365]</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.986313</td>\n",
       "      <td>2306</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.145904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.299600</td>\n",
       "      <td>1.701986</td>\n",
       "      <td>0.060512</td>\n",
       "      <td>[0.39774696707105717, 0.12212708427219468, 0.03708920187793427, 0.007839294463498285]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.144823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.266200</td>\n",
       "      <td>1.712359</td>\n",
       "      <td>0.058241</td>\n",
       "      <td>[0.3969631236442516, 0.12184115523465704, 0.036671368124118475, 0.0068694798822374874]</td>\n",
       "      <td>0.985785</td>\n",
       "      <td>0.985885</td>\n",
       "      <td>2305</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.236400</td>\n",
       "      <td>1.719782</td>\n",
       "      <td>0.055346</td>\n",
       "      <td>[0.3914930555555556, 0.11602708803611739, 0.03433678269049859, 0.006381934216985763]</td>\n",
       "      <td>0.985351</td>\n",
       "      <td>0.985458</td>\n",
       "      <td>2304</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.237700</td>\n",
       "      <td>1.721065</td>\n",
       "      <td>0.052667</td>\n",
       "      <td>[0.3886481802426343, 0.11446597566471384, 0.03380281690140845, 0.005389514943655071]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.139121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.276500</td>\n",
       "      <td>1.724658</td>\n",
       "      <td>0.055435</td>\n",
       "      <td>[0.39090909090909093, 0.11481314723097703, 0.03470919324577861, 0.006363191385217817]</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.988024</td>\n",
       "      <td>2310</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.263300</td>\n",
       "      <td>1.725254</td>\n",
       "      <td>0.052718</td>\n",
       "      <td>[0.38951473136915077, 0.11626858945470933, 0.03333333333333333, 0.005389514943655071]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.139621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.246600</td>\n",
       "      <td>1.723452</td>\n",
       "      <td>0.051266</td>\n",
       "      <td>[0.39168110918544197, 0.11536728255971158, 0.03286384976525822, 0.004899559039686428]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.139797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>1.272600</td>\n",
       "      <td>1.716063</td>\n",
       "      <td>0.050283</td>\n",
       "      <td>[0.39166304819800263, 0.11743450767841011, 0.033411764705882356, 0.0044204322200392925]</td>\n",
       "      <td>0.984917</td>\n",
       "      <td>0.985030</td>\n",
       "      <td>2303</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.205600</td>\n",
       "      <td>1.719458</td>\n",
       "      <td>0.052180</td>\n",
       "      <td>[0.3933217692974848, 0.11682453766350925, 0.03477443609022556, 0.004904364884747425]</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.986313</td>\n",
       "      <td>2306</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>1.197400</td>\n",
       "      <td>1.723540</td>\n",
       "      <td>0.054743</td>\n",
       "      <td>[0.39315127871694844, 0.11632100991884581, 0.035227806481916396, 0.0058823529411764705]</td>\n",
       "      <td>0.986653</td>\n",
       "      <td>0.986741</td>\n",
       "      <td>2307</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.215200</td>\n",
       "      <td>1.725149</td>\n",
       "      <td>0.053473</td>\n",
       "      <td>[0.39627544391511477, 0.11756756756756757, 0.0342562177381511, 0.0053868756121449556]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>1.234900</td>\n",
       "      <td>1.720285</td>\n",
       "      <td>0.059389</td>\n",
       "      <td>[0.39601386481802425, 0.11987381703470032, 0.03755868544600939, 0.007349338559529643]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>1.233800</td>\n",
       "      <td>1.715716</td>\n",
       "      <td>0.058251</td>\n",
       "      <td>[0.3965367965367965, 0.12156686177397569, 0.036585365853658534, 0.006852667645619187]</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.988024</td>\n",
       "      <td>2310</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.144081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.235000</td>\n",
       "      <td>1.725370</td>\n",
       "      <td>0.058562</td>\n",
       "      <td>[0.3975747076656561, 0.11936936936936937, 0.038010323791647115, 0.0068560235063663075]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.144081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.188300</td>\n",
       "      <td>1.724451</td>\n",
       "      <td>0.059440</td>\n",
       "      <td>[0.3954997836434444, 0.12016201620162016, 0.03750586029067042, 0.007338551859099804]</td>\n",
       "      <td>0.988385</td>\n",
       "      <td>0.988452</td>\n",
       "      <td>2311</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>1.154300</td>\n",
       "      <td>1.736236</td>\n",
       "      <td>0.058141</td>\n",
       "      <td>[0.39454309224772627, 0.11981981981981982, 0.03707179727827311, 0.0068560235063663075]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>1.174400</td>\n",
       "      <td>1.740855</td>\n",
       "      <td>0.058784</td>\n",
       "      <td>[0.39313640312771503, 0.11793944871215545, 0.0371939736346516, 0.007371007371007371]</td>\n",
       "      <td>0.984483</td>\n",
       "      <td>0.984602</td>\n",
       "      <td>2302</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>1.189400</td>\n",
       "      <td>1.740168</td>\n",
       "      <td>0.057216</td>\n",
       "      <td>[0.39045553145336226, 0.11687725631768953, 0.03620122237893747, 0.0068694798822374874]</td>\n",
       "      <td>0.985785</td>\n",
       "      <td>0.985885</td>\n",
       "      <td>2305</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.156100</td>\n",
       "      <td>1.739370</td>\n",
       "      <td>0.053585</td>\n",
       "      <td>[0.3919445647466436, 0.11666666666666667, 0.035194744251525106, 0.0053868756121449556]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>1.190500</td>\n",
       "      <td>1.738953</td>\n",
       "      <td>0.055149</td>\n",
       "      <td>[0.3932438284971849, 0.11801801801801802, 0.03566400750821211, 0.005876591576885406]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>1.184800</td>\n",
       "      <td>1.739107</td>\n",
       "      <td>0.050924</td>\n",
       "      <td>[0.389779125162408, 0.11441441441441441, 0.0323791647114031, 0.004897159647404506]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.139071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>1.219700</td>\n",
       "      <td>1.739511</td>\n",
       "      <td>0.054598</td>\n",
       "      <td>[0.39288811795316564, 0.11682453766350925, 0.03477443609022556, 0.005885237861696911]</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.986313</td>\n",
       "      <td>2306</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>1.202100</td>\n",
       "      <td>1.742476</td>\n",
       "      <td>0.054281</td>\n",
       "      <td>[0.393058568329718, 0.1141696750902527, 0.034790785143394454, 0.005888125613346418]</td>\n",
       "      <td>0.985785</td>\n",
       "      <td>0.985885</td>\n",
       "      <td>2305</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.189400</td>\n",
       "      <td>1.743721</td>\n",
       "      <td>0.054531</td>\n",
       "      <td>[0.39566160520607374, 0.11552346570397112, 0.034790785143394454, 0.005888125613346418]</td>\n",
       "      <td>0.985785</td>\n",
       "      <td>0.985885</td>\n",
       "      <td>2305</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>1.234400</td>\n",
       "      <td>1.743824</td>\n",
       "      <td>0.054956</td>\n",
       "      <td>[0.39418907198612313, 0.11637347767253045, 0.03571428571428571, 0.005885237861696911]</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.986313</td>\n",
       "      <td>2306</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>1.202400</td>\n",
       "      <td>1.741549</td>\n",
       "      <td>0.056535</td>\n",
       "      <td>[0.3944516688339835, 0.11857529305680793, 0.03616721465476749, 0.006372549019607843]</td>\n",
       "      <td>0.986653</td>\n",
       "      <td>0.986741</td>\n",
       "      <td>2307</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>1.231300</td>\n",
       "      <td>1.741878</td>\n",
       "      <td>0.046671</td>\n",
       "      <td>[0.39298093587521665, 0.11446597566471384, 0.0323943661971831, 0.0034296913277804997]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.139459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>1.177500</td>\n",
       "      <td>1.739148</td>\n",
       "      <td>0.055861</td>\n",
       "      <td>[0.395580589254766, 0.11716989634970708, 0.03474178403755868, 0.006369426751592357]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.175900</td>\n",
       "      <td>1.741694</td>\n",
       "      <td>0.057966</td>\n",
       "      <td>[0.3964471403812825, 0.11942316358720144, 0.036619718309859155, 0.006859382655560999]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>1.144200</td>\n",
       "      <td>1.754241</td>\n",
       "      <td>0.056689</td>\n",
       "      <td>[0.3957520589510186, 0.11947700631199279, 0.03616721465476749, 0.006372549019607843]</td>\n",
       "      <td>0.986653</td>\n",
       "      <td>0.986741</td>\n",
       "      <td>2307</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>1.191500</td>\n",
       "      <td>1.762848</td>\n",
       "      <td>0.056143</td>\n",
       "      <td>[0.39315127871694844, 0.11722272317403065, 0.035697510568341945, 0.006372549019607843]</td>\n",
       "      <td>0.986653</td>\n",
       "      <td>0.986741</td>\n",
       "      <td>2307</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>1.172900</td>\n",
       "      <td>1.760394</td>\n",
       "      <td>0.056770</td>\n",
       "      <td>[0.39428076256499134, 0.11897251013970257, 0.036619718309859155, 0.006369426751592357]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>1.179600</td>\n",
       "      <td>1.758567</td>\n",
       "      <td>0.054189</td>\n",
       "      <td>[0.3930735930735931, 0.11841512832057632, 0.036116322701688554, 0.0053842388644150755]</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.988024</td>\n",
       "      <td>2310</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.204400</td>\n",
       "      <td>1.758567</td>\n",
       "      <td>0.053247</td>\n",
       "      <td>[0.39428076256499134, 0.11626858945470933, 0.03427230046948357, 0.005389514943655071]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>1.105100</td>\n",
       "      <td>1.756117</td>\n",
       "      <td>0.048303</td>\n",
       "      <td>[0.39298093587521665, 0.1149166291122127, 0.0323943661971831, 0.0039196472317491425]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.139747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>1.155600</td>\n",
       "      <td>1.754643</td>\n",
       "      <td>0.049726</td>\n",
       "      <td>[0.39081455805892545, 0.11536728255971158, 0.0323943661971831, 0.004409603135717786]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.139409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>1.183600</td>\n",
       "      <td>1.754969</td>\n",
       "      <td>0.049948</td>\n",
       "      <td>[0.39228435197225836, 0.11541929666366095, 0.03287928604978863, 0.004411764705882353]</td>\n",
       "      <td>0.986653</td>\n",
       "      <td>0.986741</td>\n",
       "      <td>2307</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.139860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>1.093800</td>\n",
       "      <td>1.756112</td>\n",
       "      <td>0.054596</td>\n",
       "      <td>[0.3925476603119584, 0.1167192429022082, 0.03474178403755868, 0.005879470847623714]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.117100</td>\n",
       "      <td>1.756192</td>\n",
       "      <td>0.054527</td>\n",
       "      <td>[0.3919445647466436, 0.11621621621621622, 0.034725480994838104, 0.005876591576885406]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>1.120600</td>\n",
       "      <td>1.756290</td>\n",
       "      <td>0.054474</td>\n",
       "      <td>[0.3919445647466436, 0.11576576576576576, 0.034725480994838104, 0.005876591576885406]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>1.203900</td>\n",
       "      <td>1.758777</td>\n",
       "      <td>0.057278</td>\n",
       "      <td>[0.3938474870017331, 0.11762054979720594, 0.03568075117370892, 0.006859382655560999]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>1.195400</td>\n",
       "      <td>1.758225</td>\n",
       "      <td>0.057575</td>\n",
       "      <td>[0.3938474870017331, 0.11852185669220369, 0.03615023474178404, 0.006859382655560999]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>1.102600</td>\n",
       "      <td>1.758691</td>\n",
       "      <td>0.056018</td>\n",
       "      <td>[0.3925476603119584, 0.11626858945470933, 0.03568075117370892, 0.006369426751592357]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.158400</td>\n",
       "      <td>1.763472</td>\n",
       "      <td>0.056417</td>\n",
       "      <td>[0.3923776526634907, 0.11801801801801802, 0.03613327076489911, 0.006366307541625857]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>1.228300</td>\n",
       "      <td>1.764161</td>\n",
       "      <td>0.056127</td>\n",
       "      <td>[0.39271781534460337, 0.11722272317403065, 0.035697510568341945, 0.006372549019607843]</td>\n",
       "      <td>0.986653</td>\n",
       "      <td>0.986741</td>\n",
       "      <td>2307</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>1.141700</td>\n",
       "      <td>1.763505</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>[0.39428076256499134, 0.11807120324470483, 0.03568075117370892, 0.006369426751592357]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>1.120900</td>\n",
       "      <td>1.763565</td>\n",
       "      <td>0.056688</td>\n",
       "      <td>[0.395580589254766, 0.11942316358720144, 0.03615023474178404, 0.006369426751592357]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.143018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>1.183800</td>\n",
       "      <td>1.764465</td>\n",
       "      <td>0.053597</td>\n",
       "      <td>[0.39454309224772627, 0.11756756756756757, 0.034725480994838104, 0.0053868756121449556]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.154300</td>\n",
       "      <td>1.764325</td>\n",
       "      <td>0.055142</td>\n",
       "      <td>[0.39454309224772627, 0.11756756756756757, 0.03566400750821211, 0.005876591576885406]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>1.126500</td>\n",
       "      <td>1.766459</td>\n",
       "      <td>0.054922</td>\n",
       "      <td>[0.3949761801645734, 0.11711711711711711, 0.035194744251525106, 0.005876591576885406]</td>\n",
       "      <td>0.987519</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>2309</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>1.099200</td>\n",
       "      <td>1.768383</td>\n",
       "      <td>0.054724</td>\n",
       "      <td>[0.39471403812824957, 0.11716989634970708, 0.03474178403755868, 0.005879470847623714]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>1.135500</td>\n",
       "      <td>1.769023</td>\n",
       "      <td>0.056194</td>\n",
       "      <td>[0.3951473136915078, 0.11852185669220369, 0.035211267605633804, 0.006369426751592357]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>1.100900</td>\n",
       "      <td>1.768669</td>\n",
       "      <td>0.055050</td>\n",
       "      <td>[0.39428076256499134, 0.11852185669220369, 0.035211267605633804, 0.005879470847623714]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.142116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>1.137400</td>\n",
       "      <td>1.768562</td>\n",
       "      <td>0.054664</td>\n",
       "      <td>[0.39298093587521665, 0.11716989634970708, 0.03474178403755868, 0.005879470847623714]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.141326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>1.176400</td>\n",
       "      <td>1.768544</td>\n",
       "      <td>0.054513</td>\n",
       "      <td>[0.39168110918544197, 0.11626858945470933, 0.03474178403755868, 0.005879470847623714]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>1.124000</td>\n",
       "      <td>1.768501</td>\n",
       "      <td>0.054513</td>\n",
       "      <td>[0.39168110918544197, 0.11626858945470933, 0.03474178403755868, 0.005879470847623714]</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>2308</td>\n",
       "      <td>2338</td>\n",
       "      <td>0.140762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 89\n",
      "  Batch size = 64\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1370, training_loss=1.5358056969016138, metrics={'train_runtime': 2469.9737, 'train_samples_per_second': 35.296, 'train_steps_per_second': 0.555, 'total_flos': 9804249699287040.0, 'train_loss': 1.5358056969016138, 'epoch': 10.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "-cCGiOu4h5KI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in gpt2-netflix-model/config.json\n",
      "Model weights saved in gpt2-netflix-model/pytorch_model.bin\n",
      "tokenizer config file saved in gpt2-netflix-model/tokenizer_config.json\n",
      "Special tokens file saved in gpt2-netflix-model/special_tokens_map.json\n",
      "added tokens file saved in gpt2-netflix-model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('gpt2-netflix-model/tokenizer_config.json',\n",
       " 'gpt2-netflix-model/special_tokens_map.json',\n",
       " 'gpt2-netflix-model/vocab.json',\n",
       " 'gpt2-netflix-model/merges.txt',\n",
       " 'gpt2-netflix-model/added_tokens.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"gpt2-netflix-model\")\n",
    "tokenizer.save_pretrained(\"gpt2-netflix-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "wvUde6842UGH"
   },
   "outputs": [],
   "source": [
    "artifact_name = \"gpt2-netflix-hf\"\n",
    "artifact_type = \"model\"\n",
    "artifact_description = \"GPT2 model finetuned as per this article: https://www.kaggle.com/code/nulldata/fine-tuning-gpt-2-to-generate-netlfix-descriptions/notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "69u7XOP21eo4"
   },
   "outputs": [],
   "source": [
    "model_artifact = wandb.Artifact(name=artifact_name, type=artifact_type, description=artifact_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "1hybMByn4HoM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./gpt2-netflix-model)... Done. 9.4s\n"
     ]
    }
   ],
   "source": [
    "model_artifact.add_dir(f\"gpt2-netflix-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "aborted",
     "timestamp": 1665424273339,
     "user": {
      "displayName": "Anish Shah",
      "userId": "05913492621931233323"
     },
     "user_tz": 240
    },
    "id": "n_o3XRHx20ch"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f8c701b5a50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.log_artifact(model_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1665424273345,
     "user": {
      "displayName": "Anish Shah",
      "userId": "05913492621931233323"
     },
     "user_tz": 240
    },
    "id": "lnl16ePJ51Oq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNgZ4jdKzvuBnHh61XfRGol",
   "collapsed_sections": [],
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m97"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00159f4301e24fd983196b2bb34085b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "185bc02c28d743b9a5142767a1ecbd62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4101a1f8b3cd4cf1a14857f8563d396d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2db562c04034a8b948c64ab7529b719",
      "placeholder": "​",
      "style": "IPY_MODEL_185bc02c28d743b9a5142767a1ecbd62",
      "value": ""
     }
    },
    "47f1971420aa4e95baf39f927ec38757": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "764a9f98d95041348ba29b2c0f7d31e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da751070ba884c9298d1e2afa8b567c1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_47f1971420aa4e95baf39f927ec38757",
      "value": 0
     }
    },
    "d13385b298414e0f8d14ece8ae71317d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da751070ba884c9298d1e2afa8b567c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "dc1c9d6de8d143579ca742460a8cfba6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d13385b298414e0f8d14ece8ae71317d",
      "placeholder": "​",
      "style": "IPY_MODEL_ebbfda788fdd470f97dd977eef21d75f",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "ebbfda788fdd470f97dd977eef21d75f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2db562c04034a8b948c64ab7529b719": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4724017933549c4bb9ed4e6db07f133": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4101a1f8b3cd4cf1a14857f8563d396d",
       "IPY_MODEL_764a9f98d95041348ba29b2c0f7d31e9",
       "IPY_MODEL_dc1c9d6de8d143579ca742460a8cfba6"
      ],
      "layout": "IPY_MODEL_00159f4301e24fd983196b2bb34085b3"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
